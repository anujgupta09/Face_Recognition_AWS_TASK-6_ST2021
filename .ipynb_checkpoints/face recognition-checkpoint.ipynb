{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-13079aa311fa>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all good 1\n",
      "all good 3.2\n",
      "Face not found\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "Face not found\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "all good 3.2\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "all good 3.2\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('harcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "print(\"all good 1\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"all good 3.2\")\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-29-44f0c04526e4>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all good 1\n",
      "all good  1\n",
      "all good  2\n",
      "all good  3\n",
      "all good  4\n",
      "all good  5\n",
      "all good  6\n",
      "all good  7\n",
      "all good  8\n",
      "all good  9\n",
      "all good  10\n",
      "all good  11\n",
      "all good  12\n",
      "all good  13\n",
      "all good  14\n",
      "all good  15\n",
      "all good  16\n",
      "all good  17\n",
      "all good  18\n",
      "all good  19\n",
      "all good  20\n",
      "all good  21\n",
      "all good  22\n",
      "all good  23\n",
      "all good  24\n",
      "all good  25\n",
      "all good  26\n",
      "all good  27\n",
      "all good  28\n",
      "all good  29\n",
      "all good  30\n",
      "all good  31\n",
      "all good  32\n",
      "all good  33\n",
      "all good  34\n",
      "all good  35\n",
      "all good  36\n",
      "all good  37\n",
      "all good  38\n",
      "all good  39\n",
      "all good  40\n",
      "all good  41\n",
      "all good  42\n",
      "all good  43\n",
      "all good  44\n",
      "all good  45\n",
      "all good  46\n",
      "all good  47\n",
      "all good  48\n",
      "all good  49\n",
      "all good  50\n",
      "all good  51\n",
      "all good  52\n",
      "all good  53\n",
      "all good  54\n",
      "all good  55\n",
      "all good  56\n",
      "all good  57\n",
      "all good  58\n",
      "all good  59\n",
      "all good  60\n",
      "all good  61\n",
      "all good  62\n",
      "all good  63\n",
      "all good  64\n",
      "all good  65\n",
      "all good  66\n",
      "all good  67\n",
      "all good  68\n",
      "all good  69\n",
      "all good  70\n",
      "all good  71\n",
      "all good  72\n",
      "all good  73\n",
      "all good  74\n",
      "all good  75\n",
      "all good  76\n",
      "all good  77\n",
      "all good  78\n",
      "all good  79\n",
      "all good  80\n",
      "all good  81\n",
      "all good  82\n",
      "all good  83\n",
      "all good  84\n",
      "all good  85\n",
      "all good  86\n",
      "all good  87\n",
      "all good  88\n",
      "all good  89\n",
      "all good  90\n",
      "all good  91\n",
      "all good  92\n",
      "all good  93\n",
      "all good  94\n",
      "all good  95\n",
      "all good  96\n",
      "all good  97\n",
      "all good  98\n",
      "all good  99\n",
      "all good  100\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('harcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "print(\"all good 1\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        print(\"all good \",count)\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(     (    (   (  ( Model trained sucessefully )  )   )    )     )\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "#model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "Anuj_face_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model\n",
    "Anuj_face_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"(     (    (   (  ( Model trained sucessefully )  )   )    )     )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user2/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "#model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "#model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "itesh_face_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model\n",
    "Nitesh_face_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"(     (    (   (  ( Model  >> 2 << trained sucessefully )  )   )    )     )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-30-298967393c30>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():  # == instead of is here\n"
     ]
    }
   ],
   "source": [
    "#Anuj_face_model = cv2.face_LBPHFaceRecognizer.read('anuj.yml')\n",
    "# = model.read(\"anuj.yml\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('harcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():  # == instead of is here\n",
    "        return img, []\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results  = Anuj_face_model.predict(face)\n",
    "        results2 = Nitesh_face_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User 1'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if results2[1] < 500:\n",
    "            confidence2 = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User 2'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        if confidence >confidence2:\n",
    "            if confidence > 87:\n",
    "                cv2.putText(image, \"Hey Anuj\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition SUCCESS',image)\n",
    "                #put ur logic here\n",
    "                print(\"SSSSSSSSSSSSSSSSSSSUUUUCESSSSSSSSSSSSSSSSSSS\")\n",
    "                #end it here\n",
    "                break\n",
    "            else:\n",
    "                cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "        else:  \n",
    "            if confidence2 > 87:\n",
    "                cv2.putText(image, \"Hey Anuj\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition SUCCESS',image)\n",
    "                #put ur logic here\n",
    "                print(\"SSSSSSSSSSSSSSSSSSSUUUUCESSSSSSSSSSSSSSSSSSS\")\n",
    "                #end it here\n",
    "                break\n",
    "            else:\n",
    "                cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "                cv2.imshow('Face Recognition', image )\n",
    "\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
