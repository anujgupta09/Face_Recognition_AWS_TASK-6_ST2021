{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###################################### create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-10-70921784e0b2>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "def training_data_creation(ur_name,no_of_photos=10):\n",
    "    #ur_name = \"anuj\"       \n",
    "    path_of_user = './faces/'+ur_name+'/'     # './faces/(ur_name)/'\n",
    "    \n",
    "    #creating folder dynamically\n",
    "    os.makedirs(\"faces/\"+ur_name)\n",
    "    \n",
    "    # Load HAAR face classifier\n",
    "    face_classifier = cv2.CascadeClassifier('harcascade_frontalface_default.xml')\n",
    "\n",
    "    # Load functions\n",
    "    def face_extractor(img):\n",
    "        # Function detects faces and returns the cropped face\n",
    "        # If no face detected, it returns the input image\n",
    "    \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "        if faces is ():\n",
    "            return None\n",
    "        \n",
    "        # Crop all faces found\n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h, x:x+w]\n",
    "    \n",
    "        return cropped_face\n",
    "    \n",
    "    # Initialize Webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    # Collect  samples of your face from webcam input\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save file in specified directory with unique name\n",
    "            file_name_path = path_of_user + str(count) + '.jpg'\n",
    "            print(file_name_path)\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "    \n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Cropper', face)\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "        if cv2.waitKey(1) == 13 or count == no_of_photos:  #13 is the Enter Key\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()      \n",
    "    print(\"SAMPLE for user >> \",ur_name,\" << collected\")\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "./faces/parth1234/1.jpg\n",
      "Face not found\n",
      "Face not found\n",
      "./faces/parth1234/2.jpg\n",
      "Face not found\n",
      "./faces/parth1234/3.jpg\n",
      "./faces/parth1234/4.jpg\n",
      "./faces/parth1234/5.jpg\n",
      "./faces/parth1234/6.jpg\n",
      "./faces/parth1234/7.jpg\n",
      "./faces/parth1234/8.jpg\n",
      "./faces/parth1234/9.jpg\n",
      "./faces/parth1234/10.jpg\n",
      "SAMPLE for user >>  parth1234  << collected\n"
     ]
    }
   ],
   "source": [
    "training_data_creation(ur_name='parth1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "##########################################Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "\n",
    "    # Get the training data we previously made\n",
    "    data_path = path_of_user\n",
    "    onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "    # Create arrays for training data and labels\n",
    "    Training_Data, Labels = [], []\n",
    "\n",
    "    # Open training images in our datapath\n",
    "    # Create a numpy array for training data\n",
    "    for i, files in enumerate(onlyfiles):\n",
    "        image_path = data_path + onlyfiles[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "    \n",
    "    # Create a numpy array for both training data and labels\n",
    "    Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "    # Initialize facial recognizer\n",
    "    #model = cv2.face.createLBPHFaceRecognizer()\n",
    "    # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "    # pip install opencv-contrib-python\n",
    "    #model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "    Anuj_face_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "    # Let's train our model\n",
    "    Anuj_face_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "    print(\n",
    "\"\"\"\n",
    ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "(     (    (   (  ( Model trained sucessefully )  )   )    )     )\n",
    "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\"\"\")\n",
    "    ################################## saving model\n",
    "    def saving_model():\n",
    "        Anuj_face_model.save('./models/anuj.yml')\n",
    "        print(\"Models saved\")\n",
    "    saving_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "################################## reading saved model\n",
    "def reading_saved_model():\n",
    "    global Anuj_face_saved_model\n",
    "    Anuj_face_saved_model = cv2.face_LBPHFaceRecognizer.create()\n",
    "    Anuj_face_saved_model.read('./models/anuj.yml')\n",
    "    print('Model loaded')\n",
    "reading_saved_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mail send\n"
     ]
    }
   ],
   "source": [
    "import passwords\n",
    "import whatsup\n",
    "import mail\n",
    "whatsup_no='8796588001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-7-7e729882113e>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():  # == instead of is here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes or no yes\n",
      "\n",
      "                PRESS 1 for sending whatsup message\n",
      "                PRESS 2 for gmail\n",
      "                      \n",
      "Enter your decision : 1\n",
      "In 12 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n",
      "Message Sent to 8796588001\n",
      "SSSSSSSSSSSSSSSSSSSUUUUCESSSSSSSSSSSSSSSSSSS\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('harcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():  # == instead of is here\n",
    "        return img, []\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        \n",
    "        results = Anuj_face_saved_model.predict(face)\n",
    "        \n",
    "\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    " \n",
    "        if confidence > 92 :\n",
    "            permission = (input(\"yes or no \"))\n",
    "            if permission == 'yes':\n",
    "                cv2.putText(image, \"Hey Anuj\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Recognition SUCCESS',image)\n",
    "            \n",
    "                #put ur logic here##########################################################\n",
    "                print(\"\"\"\n",
    "                PRESS 1 for sending whatsup message\n",
    "                PRESS 2 for gmail\n",
    "                      \"\"\")\n",
    "                decision = int(input(\"Enter your decision : \"))\n",
    "                if decision == 1:\n",
    "                    whatsup.send_whatsup_msg(whatsup_no)\n",
    "                if decision == 2:\n",
    "                    mail.mail_function()\n",
    "                print(\"SSSSSSSSSSSSSSSSSSSUUUUCESSSSSSSSSSSSSSSSSSS\")\n",
    "                #end it here################################################################\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
